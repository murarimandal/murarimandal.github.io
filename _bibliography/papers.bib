---
---

@string{aps = {American Physical Society,}}

@misc{sanyal2025orgaccessbenchmarkrolebased,
      title={OrgAccess: A Benchmark for Role Based Access Control in Organization Scale LLMs}, 
      author={Debdeep Sanyal and Umakanta Maharana and Yash Sinha and Hong Ming Tan and Shirish Karande and Mohan Kankanhalli and Murari Mandal},
      year={2025},
      eprint={2505.19165},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.19165}, 
      pdf={https://arxiv.org/pdf/2505.19165}, 
      sourcecode={https://github.com/respailab/orgaccess},
      preview={orgaccess.png},
}

@misc{sanyal2025investigatingpedagogicalteacherstudent,
      title={Investigating Pedagogical Teacher and Student LLM Agents: Genetic Adaptation Meets Retrieval Augmented Generation Across Learning Style}, 
      author={Debdeep Sanyal and Agniva Maiti and Umakanta Maharana and Dhruv Kumar and Ankur Mali and C. Lee Giles and Murari Mandal},
      year={2025},
      eprint={2505.19173},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.19173}, 
      preview={pedagogy.png},
}

@misc{sharma2025waysbreakcopyrightlaw,
      title={Nine Ways to Break Copyright Law and Why Our LLM Won't: A Fair Use Aligned Generation Framework}, 
      author={Aakash Sen Sharma and Debdeep Sanyal and Priyansh Srivastava and Sundar Atreya H. and Shirish Karande and Mohan Kankanhalli and Murari Mandal},
      year={2025},
      eprint={2505.23788},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.23788}, 
      pdf={https://arxiv.org/pdf/2503.23788}, 
      preview={break.png},
}

@misc{roy2025guardiansgenerationdynamicinferencetime,
      title={Guardians of Generation: Dynamic Inference-Time Copyright Shielding with Adaptive Guidance for AI Image Generation}, 
      author={Soham Roy and Abhishek Mishra and Shirish Karande and Murari Mandal},
      year={2025},
      eprint={2503.16171},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.16171}, 
      pdf={https://arxiv.org/pdf/2503.16171}, 
      sourcecode={https://respailab.github.io/gog/},
      preview={gog.png},
}

@misc{maharana2025rightpredictionwrongreasoning,
      title={Right Prediction, Wrong Reasoning: Uncovering LLM Misalignment in RA Disease Diagnosis}, 
      sourcecode={https://respailab.github.io/rpwr.github.io/},
      author={Umakanta Maharana and Sarthak Verma and Avarna Agarwal and Prakashini Mruthyunjaya and Dwarikanath Mahapatra and Sakir Ahmed and Murari Mandal},
      year={2025},
      eprint={2504.06581},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.06581}, 
      note={This paper discusses the implications of LLM misalignment in medical diagnostics.},
      preview={rpwr.png},
      pdf={https://arxiv.org/pdf/2504.06581.pdf},
      keywords={LLM misalignment, RA disease diagnosis, medical diagnostics, AI ethics, machine learning},
      journal={arXiv preprint arXiv:2504.06581},
}

@article{Chundawat2024ConDaFF,
  title={ConDa: Fast Federated Unlearning with Contribution Dampening},
  author={Vikram S Chundawat and Pushkar Niroula and Prasanna Dhungana and Stefan Schoepf and Murari Mandal and Alexandra Brintrup},
  journal={ArXiv},
  year={2024},
  volume={abs/2410.04144},
  url={https://api.semanticscholar.org/CorpusID:273186546},
  abstract={Federated learning (FL) has enabled collaborative model training across decentralized data sources or clients. While adding new participants to a shared model does not pose great technical hurdles, the removal of a participant and their related information contained in the shared model remains a challenge. To address this problem, federated unlearning has emerged as a critical research direction, seeking to remove information from globally trained models without harming the model performance on the remaining data. Most modern federated unlearning methods use costly approaches such as the use of remaining clients data to retrain the global model or methods that would require heavy computation on client or server side. We introduce Contribution Dampening (ConDa), a framework that performs efficient unlearning by tracking down the parameters which affect the global model for each client and performs synaptic dampening on the parameters of the global model that have privacy infringing contributions from the forgetting client. Our technique does not require clients data or any kind of retraining and it does not put any computational overhead on either the client or server side. We perform experiments on multiple datasets and demonstrate that ConDa is effective to forget a client's data. In experiments conducted on the MNIST, CIFAR10, and CIFAR100 datasets, ConDa proves to be the fastest federated unlearning method, outperforming the nearest state of the art approach by at least 100x. Our emphasis is on the non-IID Federated Learning setting, which presents the greatest challenge for unlearning. Additionally, we validate ConDa's robustness through backdoor and membership inference attacks. We envision this work as a crucial component for FL in adhering to legal and ethical requirements.},
  preview={conda.png},
  pdf={https://arxiv.org/pdf/2410.04144},
}

@article{sanyal2025alu,
  title={ALU: Agentic LLM Unlearning},
  author={Sanyal, Debdeep and Mandal, Murari},
  journal={arXiv preprint arXiv:2502.00406},
  year={2025},
  abstract={Information removal or suppression in large language models (LLMs) is a desired functionality, useful in AI regulation, legal compliance, safety, and privacy. LLM unlearning methods aim to remove information on demand from LLMs. Current LLM unlearning methods struggle to balance the unlearning efficacy and utility due to the competing nature of these objectives. Keeping the unlearning process computationally feasible without assuming access to the model weights is an overlooked area. We present the first agentic LLM unlearning (\texttt{ALU}) method, a multi-agent, retrain-free, model-agnostic approach to LLM unlearning that achieves effective unlearning while preserving the utility. Our \texttt{ALU} framework unlearns by involving multiple LLM agents, each designed for a specific step in the unlearning process, without the need to update model weights for any of the agents in the framework. Users can easily request any set of unlearning instances in any sequence, and \texttt{ALU} seamlessly adapts in real time. This is facilitated without requiring any changes in the underlying LLM model. Through extensive experiments on established benchmarks (TOFU, WMDP, WPU) and jailbreaking techniques (many shot, target masking, other languages), we demonstrate that \texttt{ALU} consistently stands out as the most robust LLM unlearning framework among current state-of-the-art methods while incurring a low constant-time cost. We further highlight \texttt{ALU}'s superior performance compared to existing methods when evaluated at scale. Specifically, \texttt{ALU} is assessed on up to 1000 unlearning targets, exceeding the evaluation scope of all previously proposed LLM unlearning methods.},
  preview={alu.png},
  pdf={https://arxiv.org/pdf/2502.00406},
}


@article{kirtani2025revieweval,
  title={ReviewEval: An Evaluation Framework for AI-Generated Reviews},
  author={Kirtani, Chavvi and Garg, Madhav Krishan and Prasad, Tejash and Singhal, Tanmay and Mandal, Murari and Kumar, Dhruv},
  journal={arXiv preprint arXiv:2502.11736},
  year={2025},
  abstract={The escalating volume of academic research, coupled with a shortage of qualified reviewers, necessitates innovative approaches to peer review. While large language model (LLMs) offer potential for automating this process, their current limitations include superficial critiques, hallucinations, and a lack of actionable insights. This research addresses these challenges by introducing a comprehensive evaluation framework for AI-generated reviews, that measures alignment with human evaluations, verifies factual accuracy, assesses analytical depth, and identifies actionable insights. We also propose a novel alignment mechanism that tailors LLM-generated reviews to the unique evaluation priorities of individual conferences and journals. To enhance the quality of these reviews, we introduce a self-refinement loop that iteratively optimizes the LLM's review prompts. Our framework establishes standardized metrics for evaluating AI-based review systems, thereby bolstering the reliability of AI-generated reviews in academic research.},
  preview={revieweval.png},
  pdf={https://arxiv.org/pdf/2502.11736},
}

@inproceedings{Sinha2024UnStarUW,
  title={UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs},
  author={Yash Sinha and Murari Mandal and Mohan S. Kankanhalli},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:273507947},
  abstract={The key components of machine learning are data samples for training, model for learning patterns, and loss function for optimizing accuracy. Analogously, unlearning can potentially be achieved through anti-data samples (or anti-samples), unlearning method, and reversed loss function. While prior research has explored unlearning methods and reversed loss functions, the potential of anti-samples remains largely untapped. In this paper, we introduce UnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language models (LLMs). Our contributions are threefold; first, we propose a novel concept of anti-sample-induced unlearning; second, we generate anti-samples by leveraging misleading rationales, which help reverse learned associations and accelerate the unlearning process; and third, we enable fine-grained targeted unlearning, allowing for the selective removal of specific associations without impacting related knowledge - something not achievable by previous works. Results demonstrate that anti-samples offer an efficient, targeted unlearning strategy for LLMs, opening new avenues for privacy-preserving machine learning and model modification.},
  preview={unstar.png},
  pdf={https://arxiv.org/pdf/2410.17050},
}



@article{tarun2023fast,
  abbr      = {IEEE TNNLS},
  conf      = {IEEE TNNLS},
  sourcecode = {https://github.com/vikram2000b/Fast-Machine-Unlearning},
  title     = {Fast yet effective machine unlearning},
  author    = {Tarun, Ayush K and Chundawat, Vikram S and Mandal, Murari and Kankanhalli, Mohan},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  year      = {2023},
  publisher = {IEEE},
  pdf       = {https://arxiv.org/pdf/2111.08947.pdf},
  preview   = {fast-unlearning.png},
}

@article{10097553,
  abbr     = {IEEE},
  conf     = {IEEE TIFS},
  sourcecode = {https://github.com/ayushkumartarun/zero-shot-unlearning},
  author   = {Chundawat, Vikram S. and Tarun, Ayush K. and Mandal, Murari and Kankanhalli, Mohan},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {Zero-Shot Machine Unlearning},
  year     = {2023},
  volume   = {18},
  number   = {},
  pages    = {2345-2354},
  keywords = {Data models;Training;Data privacy;Training data;Computational modeling;Regulation;Machine learning;Machine unlearning;machine learning security and privacy;data privacy},
  doi      = {10.1109/TIFS.2023.3265506},
  pdf      = {https://arxiv.org/pdf/2201.05629.pdf},
  preview  = {zero-shot-unlearning.png},
}

@inproceedings{pmlr-v202-tarun23a,
  title     = {Deep Regression Unlearning},
  sourcecode={https://github.com/ayushkumartarun/deep-regression-unlearning},
  conf      = {ICML-2023},
  ranking   = {Core A*},
  author    = {Tarun, Ayush Kumar and Chundawat, Vikram Singh and Mandal, Murari and Kankanhalli, Mohan},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  pages     = {33921--33939},
  year      = {2023},
  editor    = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume    = {202},
  series    = {Proceedings of Machine Learning Research},
  month     = {23--29 Jul},
  publisher = {PMLR},
  pdf       = {https://proceedings.mlr.press/v202/tarun23a/tarun23a.pdf},
  url       = {https://proceedings.mlr.press/v202/tarun23a.html},
  preview   = {deep-regression-unlearning.png},
  abstract  = {With the introduction of data protection and privacy regulations, it has become crucial to remove the lineage of data on demand from a machine learning (ML) model. In the last few years, there have been notable developments in machine unlearning to remove the information of certain training data efficiently and effectively from ML models. In this work, we explore unlearning for the regression problem, particularly in deep learning models. Unlearning in classification and simple linear regression has been considerably investigated. However, unlearning in deep regression models largely remains an untouched problem till now. In this work, we introduce deep regression unlearning methods that generalize well and are robust to privacy attacks. We propose the Blindspot unlearning method which uses a novel weight optimization process. A randomly initialized model, partially exposed to the retain samples and a copy of the original model are used together to selectively imprint knowledge about the data that we wish to keep and scrub off the information of the data we wish to forget. We also propose a Gaussian fine tuning method for regression unlearning. The existing unlearning metrics for classification are not directly applicable to regression unlearning. Therefore, we adapt these metrics for the regression setting. We conduct regression unlearning experiments for computer vision, natural language processing and forecasting applications. Our methods show excellent performance for all these datasets across all the metrics. Source code: https://github.com/ayu987/deep-regression-unlearning},
  selected = {true},
}

@misc{tarun2024ecoval,
  conf          = {KDD-2024},
  ranking       = {Core A*},
  sourcecode   = {https://github.com/respai-lab/ecoval},
  title         = {EcoVal: An Efficient Data Valuation Framework for Machine Learning},
  author        = {Ayush K Tarun and Vikram S Chundawat and Murari Mandal and Hong Ming Tan and Bowei Chen and Mohan Kankanhalli},
  year          = {2024},
  eprint        = {2402.09288},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  pdf           = {https://arxiv.org/pdf/2402.09288},
  preview       = {ecoval.png},
  abstract      = {Quantifying the value of data within a machine learning workflow can play a pivotal role in making more strategic decisions in machine learning initiatives. The existing Shapley value based frameworks for data valuation in machine learning are computationally expensive as they require considerable amount of repeated training of the model to obtain the Shapley value. In this paper, we introduce an efficient data valuation framework EcoVal, to estimate the value of data for machine learning models in a fast and practical manner. Instead of directly working with individual data sample, we determine the value of a cluster of similar data points. This value is further propagated amongst all the member cluster points. We show that the overall data value can be determined by estimating the intrinsic and extrinsic value of each data. This is enabled by formulating the performance of a model as a \textit{production function}, a concept which is popularly used to estimate the amount of output based on factors like labor and capital in a traditional free economic market. We provide a formal proof of our valuation technique and elucidate the principles and mechanisms that enable its accelerated performance. We demonstrate the real-world applicability of our method by showcasing its effectiveness for both in-distribution and out-of-sample data. This work addresses one of the core challenges of efficient data valuation at scale in machine learning models.},
  selected = {true},
}

@misc{sharma2024unlearningconcealmentcriticalanalysis,
title={Unlearning or Concealment? A Critical Analysis and Evaluation Metrics for Unlearning in Diffusion Models}, 
author={Aakash Sen Sharma and Niladri Sarkar and Vikram Chundawat and Ankur A Mali and Murari Mandal},
year={2024},
eprint={2409.05668},
archivePrefix={arXiv},
primaryClass={cs.LG},
url={https://arxiv.org/abs/2409.05668}, 
pdf={https://arxiv.org/pdf/2409.05668},
preview={conceal.png}
}

@misc{chatterjee2024unifiedframeworkcontinuallearning,
title={A Unified Framework for Continual Learning and Machine Unlearning}, 
author={Romit Chatterjee and Vikram Chundawat and Ayush Tarun and Ankur Mali and Murari Mandal},
year={2024},
eprint={2408.11374},
archivePrefix={arXiv},
primaryClass={cs.LG},
url={https://arxiv.org/abs/2408.11374}, 
pdf={https://arxiv.org/pdf/2408.11374v1},
preview={cont-learn.png}
}

@misc{sinha2024multimodalrecommendationunlearning,
  conf          = {AAAI-2025},
  ranking       = {Core A*},
  sourcecode   = {https://github.com/MachineUnlearn/MMRecUN},
  title={Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality Constraints}, 
  author={Yash Sinha and Murari Mandal and Mohan Kankanhalli},
  year={2025},
  eprint={2405.15328},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/33367},
  pdf={https://ojs.aaai.org/index.php/AAAI/article/view/33367/35522},
  abstract={Unlearning methods for recommender systems (RS) have emerged to address privacy issues and concerns about legal compliance. However, evolving user preferences and content licensing issues still remain unaddressed. This is particularly true in case of multi-modal recommender systems (MMRS), which aim to accommodate the growing influence of multi-modal information on user preferences. Previous unlearning methods for RS are inapplicable to MMRS due to incompatibility of multi-modal user-item behavior data graph with the matrix based representation of RS. Partitioning based methods degrade recommendation performance and incur significant overhead costs during aggregation. This paper introduces MMRecUN, a new framework for multi-modal recommendation unlearning, which, to the best of our knowledge, is the first attempt in this direction. Given the trained recommendation model and marked forget data, we devise Reverse Bayesian Personalized Ranking (BPR) objective to force the model to forget it. MMRecUN employs both reverse and forward BPR loss mechanisms to selectively attenuate the impact of interactions within the forget set while concurrently reinforcing the significance of interactions within the retain set. Our experiments demonstrate that MMRecUN outperforms baseline methods across various unlearning requests when evaluated on benchmark multi-modal recommender datasets. MMRecUN achieves recall performance improvements of up to $\mathbf{49.85%}$ compared to the baseline methods. It is up to 1.3× faster than the \textsc{Gold} model, which is trained on retain data from scratch. MMRecUN offers advantages such as superior performance in removing target elements, preservation of performance for retained elements, and zero overhead costs in comparison to previous methods.},
  preview= {multi-model unlearning.png},
}

@article{sinha2023distill,
  abbr     = {IEEE},
  conf     = {IEEE TNNLS},
  title         = {Distill to Delete: Unlearning in Graph Networks with Knowledge Distillation},
  author        = {Yash Sinha and Murari Mandal and Mohan Kankanhalli},
  year          = {2025},
  eprint        = {2309.16173},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  preview       = {distil.png},
  abstract      = {Graph unlearning has emerged as a pivotal method to delete information from a pre-trained graph neural network (GNN). One may delete nodes, a class of nodes, edges, or a class of edges. An unlearning method enables the GNN model to comply with data protection regulations (i.e., the right to be forgotten), adapt to evolving data distributions, and reduce the GPU-hours carbon footprint by avoiding repetitive retraining. Existing partitioning and aggregation-based methods have limitations due to their poor handling of local graph dependencies and additional overhead costs. More recently, GNNDelete offered a model-agnostic approach that alleviates some of these issues. Our work takes a novel approach to address these challenges in graph unlearning through knowledge distillation, as it distills to delete in GNN (D2DGN). It is a model-agnostic distillation framework where the complete graph knowledge is divided and marked for retention and deletion. It performs distillation with response-based soft targets and feature-based node embedding while minimizing KL divergence. The unlearned model effectively removes the influence of deleted graph elements while preserving knowledge about the retained graph elements. D2DGN surpasses the performance of existing methods when evaluated on various real-world graph datasets by up to 43.1% (AUC) in edge and node unlearning tasks. Other notable advantages include better efficiency, better performance in removing target elements, preservation of performance for the retained elements, and zero overhead costs. Notably, our D2DGN surpasses the state-of-the-art GNNDelete in AUC by 2.4%, improves membership inference ratio by +1.3, requires 10.2×106 fewer FLOPs per forward pass and up to 3.2× faster.},
  pdf           = {https://arxiv.org/pdf/2309.16173}
}

@article{Chundawat_Tarun_Mandal_Kankanhalli_2023,
  title        = {Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks Using an Incompetent Teacher},
  volume       = {37},
  sourcecode   = {https://github.com/vikram2000b/bad-teaching-unlearning},
  conf         = {AAAI-2023},
  ranking      = {Core A*},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/25879},
  doi          = {10.1609/aaai.v37i6.25879},
  abstractnote = {Machine unlearning has become an important area of research due to an increasing need for machine learning (ML) applications to comply with the emerging data privacy regulations. It facilitates the provision for removal of certain set or class of data from an already trained ML model without requiring retraining from scratch. Recently, several efforts have been put in to make unlearning to be effective and efficient. We propose a novel machine unlearning method by exploring the utility of competent and incompetent teachers in a student-teacher framework to induce forgetfulness. The knowledge from the competent and incompetent teachers is selectively transferred to the student to obtain a model that doesn’t contain any information about the forget data. We experimentally show that this method generalizes well, is fast and effective. Furthermore, we introduce the zero retrain forgetting (ZRF) metric to evaluate any unlearning method. Unlike the existing unlearning metrics, the ZRF score does not depend on the availability of the expensive retrained model. This makes it useful for analysis of the unlearned model after deployment as well. We present results of experiments conducted for random subset forgetting and class forgetting on various deep networks and across different application domains. Code is at: https://github.com/vikram2000b/bad-teaching- unlearning},
  number       = {6},
  journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author       = {Chundawat, Vikram S and Tarun, Ayush K and Mandal, Murari and Kankanhalli, Mohan},
  year         = {2023},
  month        = {Jun.},
  pages        = {7210-7217},
  preview      = {bad_teaching.png},
  selected = {true},
}

@article{chundawat2022universal,
  abbr = {IEEE},
  sourcecode={https://github.com/vikram2000b/tabsyndex},
  conf = {IEEE-TAI},
  title={A universal metric for robust evaluation of synthetic tabular data},
  author={Chundawat, Vikram S and Tarun, Ayush K and Mandal, Murari and Lahoti, Mukund and Narang, Pratik},
  journal={IEEE Transactions on Artificial Intelligence},
  year={2023},
  publisher={IEEE},
  sourcecode={https://github.com/vikram2000b/tabsyndex},
  preview={tabsyndex.png}
}

@InProceedings{Ancuti_2020_CVPR_Workshops,
author = {Ancuti, Codruta O. and Ancuti, Cosmin and Vasluianu, Florin-Alexandru and Timofte, Radu},
title = {NTIRE 2020 Challenge on NonHomogeneous Dehazing},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2020},
pdf={https://arxiv.org/pdf/2005.03457},
preview={ntire.png}
}

@ARTICLE{9395478,
  author={Anand, Tanmay and Sinha, Soumendu and Mandal, Murari and Chamola, Vinay and Yu, Fei Richard},
  journal={IEEE Sensors Journal}, 
  title={AgriSegNet: Deep Aerial Semantic Segmentation Framework for IoT-Assisted Precision Agriculture}, 
  year={2021},
  volume={21},
  number={16},
  pages={17581-17590},
  keywords={Agriculture;Image segmentation;Feature extraction;Semantics;Monitoring;Head;Deep learning;Deep learning;IoT;agriculture;agriculture-vision;semantic segmentation;sensors},
  doi={10.1109/JSEN.2021.3071290},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9395478},
  preview={agrisegnet.png}
  }

@ARTICLE{9167446,
  author={Mehra, Aryan and Mandal, Murari and Narang, Pratik and Chamola, Vinay},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={ReViewNet: A Fast and Resource Optimized Network for Enabling Safe Autonomous Driving in Hazy Weather Conditions}, 
  year={2021},
  volume={22},
  number={7},
  pages={4256-4266},
  keywords={Image color analysis;Atmospheric modeling;Autonomous vehicles;Task analysis;Scattering;Meteorology;Gallium nitride;Vehicular vision;dehazing;adverse weather;deep learning;resource-efficient;lightweight},
  doi={10.1109/TITS.2020.3013099},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9167446},
  preview={reviewnet.png}
  }

@ARTICLE{9436046,
  author={Mandal, Murari and Vipparthi, Santosh Kumar},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={An Empirical Review of Deep Learning Frameworks for Change Detection: Model Design, Experimental Frameworks, Challenges and Research Needs}, 
  year={2022},
  volume={23},
  number={7},
  pages={6101-6122},
  keywords={Deep learning;Training;Task analysis;Data models;Computational modeling;Cameras;Benchmark testing;Change detection;survey;background subtraction;deep learning;scene independence},
  doi={10.1109/TITS.2021.3077883},
  pdf={https://arxiv.org/pdf/2105.01342},
  preview   = {empirical.png},
  }

@ARTICLE{8755462,
  author={Mandal, Murari and Shah, Manal and Meena, Prashant and Devi, Sanhita and Vipparthi, Santosh Kumar},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={AVDNet: A Small-Sized Vehicle Detection Network for Aerial Visual Data}, 
  year={2020},
  volume={17},
  number={3},
  pages={494-498},
  keywords={Feature extraction;Vehicle detection;Detectors;Object detection;Visualization;Computer architecture;Histograms;Aerial scenes;automatic target detection;deep learning;remote sensing;residual features;vehicle detection},
  doi={10.1109/LGRS.2019.2923564},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8755462},
  preview={avdnet.png},
  }

@ARTICLE{9263106,
  author={Mandal, Murari and Dhar, Vansh and Mishra, Abhishek and Vipparthi, Santosh Kumar and Abdel-Mottaleb, Mohamed},
  journal={IEEE Transactions on Image Processing}, 
  title={3DCD: Scene Independent End-to-End Spatiotemporal Feature Learning Framework for Change Detection in Unseen Videos}, 
  year={2021},
  volume={30},
  number={},
  pages={546-558},
  keywords={Videos;Spatiotemporal phenomena;Feature extraction;Training;Estimation;Adaptation models;Three-dimensional displays;Change detection;background subtraction;3D-CNN;spatiotemporal;scene independence;deep learning},
  doi={10.1109/TIP.2020.3037472},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9263106},
  preview={3dcd.png}
  }

@InProceedings{Mehta_2021_WACV,
    author    = {Mehta, Aditya and Sinha, Harsh and Mandal, Murari and Narang, Pratik},
    title     = {Domain-Aware Unsupervised Hyperspectral Reconstruction for Aerial Image Dehazing},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2021},
    pages     = {413-422},
  ranking   = {Core A},
  pdf={https://openaccess.thecvf.com/content/WACV2021/papers/Mehta_Domain-Aware_Unsupervised_Hyperspectral_Reconstruction_for_Aerial_Image_Dehazing_WACV_2021_paper.pdf},
  preview={domainaware.png}
}
@InProceedings{Mehta_2020_CVPR_Workshops,
author = {Mehta, Aditya and Sinha, Harsh and Narang, Pratik and Mandal, Murari},
title = {HIDeGan: A Hyperspectral-Guided Image Dehazing GAN},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2020},
pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9150802},
preview={hidegan.png}
}
@ARTICLE{9238403,
  author={Mandal, Murari and Vipparthi, Santosh Kumar},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Scene Independency Matters: An Empirical Study of Scene Dependent and Scene Independent Evaluation for CNN-Based Change Detection}, 
  year={2022},
  volume={23},
  number={3},
  pages={2031-2044},
  keywords={Training;Deep learning;Feature extraction;Benchmark testing;Task analysis;Adaptation models;Change detection;background subtraction;scene independence;video analysis;deep learning},
  doi={10.1109/TITS.2020.3030801},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9238403},
  preview={scene.png}
  }

@INPROCEEDINGS{8803262,
  author={Mandal, Murari and Shah, Manal and Meena, Prashant and Vipparthi, Santosh Kumar},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, 
  title={SSSDET: Simple Short and Shallow Network for Resource Efficient Vehicle Detection in Aerial Scenes}, 
  year={2019},
  volume={},
  number={},
  pages={3098-3102},
  keywords={Detectors;Feature extraction;Vehicle detection;Memory management;Object detection;Convolution;Computational modeling;aerial scene;vehicle detection;deep learning;real-time;remote sensing},
  doi={10.1109/ICIP.2019.8803262},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8803262},
  preview={sssdnet.png}
  }

@ARTICLE{8894435,
  author={Mandal, Murari and Dhar, Vansh and Mishra, Abhishek and Vipparthi, Santosh Kumar},
  journal={IEEE Signal Processing Letters}, 
  title={3DFR: A Swift 3D Feature Reductionist Framework for Scene Independent Change Detection}, 
  year={2019},
  volume={26},
  number={12},
  pages={1882-1886},
  keywords={Feature extraction;Videos;Spatiotemporal phenomena;History;Three-dimensional displays;Deep learning;Kernel;Change detection;scene independent;segmentation;deep learning;spatiotemporal;reductionist},
  doi={10.1109/LSP.2019.2952253},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8894435},
  preview={3dfr.png}
  }

@InProceedings{Mandal_2020_WACV,
author = {Mandal, Murari and Kumar, Lav Kush and Saran, Mahipal Singh and vipparthi, Santosh Kumar},
title = {MotionRec: A Unified Deep Framework for Moving Object Recognition},
booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
month = {March},
year = {2020},
  ranking   = {Core A},
  pdf={https://openaccess.thecvf.com/content_WACV_2020/papers/Mandal_MotionRec_A_Unified_Deep_Framework_for_Moving_Object_Recognition_WACV_2020_paper.pdf},
  preview={motionrec.png}
}

@article{DBLP:journals/corr/abs-1906-04574,
  author       = {Kuldeep Marotirao Biradar and
                  Ayushi Gupta and
                  Murari Mandal and
                  Santosh Kumar Vipparthi},
  title        = {Challenges in Time-Stamp Aware Anomaly Detection in Traffic Videos},
  journal      = {CoRR},
  volume       = {abs/1906.04574},
  year         = {2019},
  url          = {http://arxiv.org/abs/1906.04574},
  eprinttype    = {arXiv},
  eprint       = {1906.04574},
  timestamp    = {Fri, 14 Jun 2019 09:38:24 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1906-04574.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  pdf={https://arxiv.org/pdf/1906.04574#:~:text=Anomaly%20detection%20in%20videos%20is,for%20normal%20and%20abnormal%20scenarios.},
  preview={anomalydetection.png}
}
@inproceedings{10.1145/3394171.3413934,
author = {Mandal, Murari and Kumar, Lav Kush and Vipparthi, Santosh Kumar},
title = {MOR-UAV: A Benchmark Dataset and Baselines for Moving Object Recognition in UAV Videos},
year = {2020},
ranking = {Core A*},
conf={ACM MM},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413934},
doi = {10.1145/3394171.3413934},
abstract = {Visual data collected from Unmanned Aerial Vehicles (UAVs) has opened a new frontier of computer vision that requires automated analysis of aerial images/videos. However, the existing UAV datasets primarily focus on object detection. An object detector does not differentiate between the moving and non-moving objects. Given a real-time UAV video stream, how can we both localize and classify the moving objects, i.e. perform moving object recognition (MOR) The MOR is one of the essential tasks to support various UAV vision-based applications including aerial surveillance, search and rescue, event recognition, urban and rural scene understanding.To the best of our knowledge, no labeled dataset is available for MOR evaluation in UAV videos. Therefore, in this paper, we introduce MOR-UAV, a large-scale video dataset for MOR in aerial videos. We achieve this by labeling axis-aligned bounding boxes for moving objects which requires less computational resources than producing pixel-level estimates. We annotate 89,783 moving object instances collected from 30 UAV videos, consisting of 10,948 frames in various scenarios such as weather conditions, occlusion, changing flying altitude and multiple camera views. We assigned the labels for two categories of vehicles (car and heavy vehicle). Furthermore, we propose a deep unified framework MOR-UAVNet for MOR in UAV videos. Since, this is a first attempt for MOR in UAV videos, we present 16 baseline results based on the proposed framework over the MOR-UAV dataset through quantitative and qualitative experiments. We also analyze the motion-salient regions in the network through multiple layer visualizations. The MOR-UAVNet works online at inference as it requires only few past frames. Moreover, it doesn't require predefined target initialization from user. Experiments also demonstrate that the MOR-UAV dataset is quite challenging.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {2626-2635},
numpages = {10},
keywords = {UAV, aerial vehicular vision, deep learning, moving object recognition, remote sensing},
location = {Seattle, WA, USA},
series = {MM '20},
pdf={https://arxiv.org/pdf/2008.01699},
preview={moruav.png}
}

